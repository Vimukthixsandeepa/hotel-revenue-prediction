{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "191e9791-a4c9-4bcb-af0e-68360da20a57",
   "metadata": {},
   "source": [
    "### Split the Data into Train & Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "036c8472-3c8a-41b0-a4b7-1d0fbcc13144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (21999, 29)\n",
      "Test shape: (5500, 29)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the processed dataset\n",
    "df = pd.read_csv(\"../data/processed/hotel_bookings_cleaned.csv\")\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = df.drop(columns=[\"Reservation_Status\"])  # Features\n",
    "y = df[\"Reservation_Status\"]  # Target (1=Check-in, 2=Cancel, 3=No-Show)\n",
    "\n",
    "# Split the dataset (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Train shape:\", X_train.shape)\n",
    "print(\"Test shape:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd9cc16-40e5-4e0d-8dd8-43c3e0c8f15b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d37ff8e7-37ee-413f-8ea0-b203f44b8cfc",
   "metadata": {},
   "source": [
    "### Train a Baseline Model (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171fc43a-daa0-4b12-826e-0a00a6b48fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39817b54-a42e-45bd-a457-f696e4379026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in e:\\anaconda\\envs\\hotel_env\\lib\\site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in e:\\anaconda\\envs\\hotel_env\\lib\\site-packages (from imbalanced-learn) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in e:\\anaconda\\envs\\hotel_env\\lib\\site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in e:\\anaconda\\envs\\hotel_env\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in e:\\anaconda\\envs\\hotel_env\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in e:\\anaconda\\envs\\hotel_env\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Before SMOTE: Reservation_Status\n",
      "1    16992\n",
      "2     3307\n",
      "3     1700\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Load the processed dataset\n",
    "df = pd.read_csv(\"../data/processed/hotel_bookings_cleaned.csv\")\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = df.drop(columns=[\"Reservation_Status\"])  # Features\n",
    "y = df[\"Reservation_Status\"]  # Target (1=Check-in, 2=Cancel, 3=No-Show)\n",
    "\n",
    "# Split the dataset (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "print(\"Before SMOTE:\", y_train.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c44cf309-bc98-447f-98ef-f47ae78d3540",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\hotel_env\\lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After SMOTE: Reservation_Status\n",
      "1    16992\n",
      "3    16992\n",
      "2    16992\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Apply SMOTE to balance the classes\n",
    "smote = SMOTE(sampling_strategy=\"auto\", random_state=42)\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"After SMOTE:\", y_train_sm.value_counts())  # Check the new class distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f2f9e89-91b3-4ce2-bc4d-41cc2e576a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.65      0.17      0.28      4248\n",
      "           2       0.13      0.63      0.21       827\n",
      "           3       0.53      0.36      0.43       425\n",
      "\n",
      "    accuracy                           0.26      5500\n",
      "   macro avg       0.44      0.39      0.31      5500\n",
      "weighted avg       0.56      0.26      0.28      5500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate performance\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b21fe148-09c9-44cb-97fd-c92bf5a7f30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\hotel_env\\lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.2580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\hotel_env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.5984\n",
      "Decision Tree Accuracy: 0.2465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\hotel_env\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [19:17:39] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.2593\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Encode labels to start from 0\n",
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)  # Encode original labels\n",
    "y_test_encoded = le.transform(y_test)  # Ensure the same encoding for test\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(sampling_strategy=\"auto\", random_state=42)\n",
    "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train_encoded)  # Use encoded labels\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric=\"mlogloss\")\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_sm, y_train_sm)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Convert predictions back to original labels if needed\n",
    "    y_pred = le.inverse_transform(y_pred)  \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb3f563b-0f5c-4cd7-8d6e-89a3cfa9384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Identify numerical columns\n",
    "num_cols = [\"Age\", \"Room_Rate\", \"Discount_Rate\"]  # Add other numerical columns if needed\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "X_train_sm[num_cols] = scaler.fit_transform(X_train_sm[num_cols])\n",
    "X_test[num_cols] = scaler.transform(X_test[num_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0148698f-16ee-43d7-8775-5f98f3f2a225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly Correlated Features: ['Age', 'Educational_Level', 'Income', 'Adults', 'Children', 'Babies', 'Discount_Rate', 'Room_Rate', 'Gender_M', 'Ethnicity_Asian American', 'Ethnicity_Latino', 'Ethnicity_caucasian', 'Country_region_North', 'Country_region_South', 'Country_region_West', 'Hotel_Type_City Hotel', 'Hotel_Type_Resort', 'Meal_Type_FB', 'Meal_Type_HB', 'Deposit_type_Non-Refundable', 'Deposit_type_Refundable', 'Booking_channel_Direct', 'Booking_channel_Online', 'Visted_Previously_Yes', 'Previous_Cancellations_Yes', 'Required_Car_Parking_Yes', 'Use_Promotion_Yes', 'Booking_Lead_Time', 'Total_Guests']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = X_train_sm.corr()\n",
    "\n",
    "# Find highly correlated features (threshold: 0.9)\n",
    "high_corr_features = [column for column in corr_matrix.columns if any(corr_matrix[column] > 0.9)]\n",
    "print(\"Highly Correlated Features:\", high_corr_features)\n",
    "\n",
    "# Drop them from the dataset\n",
    "X_train_sm.drop(columns=high_corr_features, inplace=True)\n",
    "X_test.drop(columns=high_corr_features, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8bfde136-4474-424d-9622-827bac1ba97b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['Age', 'Educational_Level', 'Income', 'Adults', 'Children', 'Babies', 'Discount_Rate', 'Room_Rate', 'Gender_M', 'Ethnicity_Asian American', 'Ethnicity_Latino', 'Ethnicity_caucasian', 'Country_region_North', 'Country_region_South', 'Country_region_West', 'Hotel_Type_City Hotel', 'Hotel_Type_Resort', 'Meal_Type_FB', 'Meal_Type_HB', 'Deposit_type_Non-Refundable', 'Deposit_type_Refundable', 'Booking_channel_Direct', 'Booking_channel_Online', 'Visted_Previously_Yes', 'Previous_Cancellations_Yes', 'Required_Car_Parking_Yes', 'Use_Promotion_Yes', 'Booking_Lead_Time', 'Total_Guests'] []\nexpected Booking_channel_Online, Meal_Type_FB, Ethnicity_Asian American, Use_Promotion_Yes, Babies, Gender_M, Ethnicity_caucasian, Discount_Rate, Country_region_West, Ethnicity_Latino, Total_Guests, Room_Rate, Hotel_Type_City Hotel, Income, Deposit_type_Non-Refundable, Country_region_South, Booking_Lead_Time, Meal_Type_HB, Hotel_Type_Resort, Visted_Previously_Yes, Country_region_North, Required_Car_Parking_Yes, Deposit_type_Refundable, Previous_Cancellations_Yes, Adults, Age, Booking_channel_Direct, Educational_Level, Children in input data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m xgb_model \u001b[38;5;241m=\u001b[39m XGBClassifier(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m300\u001b[39m, max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlogloss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m xgb_model\u001b[38;5;241m.\u001b[39mfit(X_train_sm, y_train_sm)\n\u001b[1;32m----> 6\u001b[0m y_pred_xgb \u001b[38;5;241m=\u001b[39m \u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXGBoost Performance:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, classification_report(y_test, y_pred_xgb))\n",
      "File \u001b[1;32mE:\\anaconda\\envs\\hotel_env\\lib\\site-packages\\xgboost\\sklearn.py:1633\u001b[0m, in \u001b[0;36mXGBClassifier.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1624\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\n\u001b[0;32m   1625\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1626\u001b[0m     X: ArrayLike,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1630\u001b[0m     iteration_range: Optional[IterationRange] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1631\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[0;32m   1632\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbosity):\n\u001b[1;32m-> 1633\u001b[0m         class_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1634\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1636\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1637\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1638\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1639\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1640\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m output_margin:\n\u001b[0;32m   1641\u001b[0m             \u001b[38;5;66;03m# If output_margin is active, simply return the scores\u001b[39;00m\n\u001b[0;32m   1642\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m class_probs\n",
      "File \u001b[1;32mE:\\anaconda\\envs\\hotel_env\\lib\\site-packages\\xgboost\\sklearn.py:1248\u001b[0m, in \u001b[0;36mXGBModel.predict\u001b[1;34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[0m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_use_inplace_predict():\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1248\u001b[0m         predts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m            \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpredict_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmargin\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1255\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1256\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n\u001b[0;32m   1257\u001b[0m             \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcupy\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=import-error\u001b[39;00m\n",
      "File \u001b[1;32mE:\\anaconda\\envs\\hotel_env\\lib\\site-packages\\xgboost\\core.py:2514\u001b[0m, in \u001b[0;36mBooster.inplace_predict\u001b[1;34m(self, data, iteration_range, predict_type, missing, validate_features, base_margin, strict_shape)\u001b[0m\n\u001b[0;32m   2512\u001b[0m     data, fns, _ \u001b[38;5;241m=\u001b[39m _transform_pandas_df(data, enable_categorical)\n\u001b[0;32m   2513\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validate_features:\n\u001b[1;32m-> 2514\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_list(data) \u001b[38;5;129;01mor\u001b[39;00m _is_tuple(data):\n\u001b[0;32m   2516\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data)\n",
      "File \u001b[1;32mE:\\anaconda\\envs\\hotel_env\\lib\\site-packages\\xgboost\\core.py:3079\u001b[0m, in \u001b[0;36mBooster._validate_features\u001b[1;34m(self, feature_names)\u001b[0m\n\u001b[0;32m   3073\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m my_missing:\n\u001b[0;32m   3074\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   3075\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mtraining data did not have the following fields: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3076\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m my_missing)\n\u001b[0;32m   3077\u001b[0m     )\n\u001b[1;32m-> 3079\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names, feature_names))\n",
      "\u001b[1;31mValueError\u001b[0m: feature_names mismatch: ['Age', 'Educational_Level', 'Income', 'Adults', 'Children', 'Babies', 'Discount_Rate', 'Room_Rate', 'Gender_M', 'Ethnicity_Asian American', 'Ethnicity_Latino', 'Ethnicity_caucasian', 'Country_region_North', 'Country_region_South', 'Country_region_West', 'Hotel_Type_City Hotel', 'Hotel_Type_Resort', 'Meal_Type_FB', 'Meal_Type_HB', 'Deposit_type_Non-Refundable', 'Deposit_type_Refundable', 'Booking_channel_Direct', 'Booking_channel_Online', 'Visted_Previously_Yes', 'Previous_Cancellations_Yes', 'Required_Car_Parking_Yes', 'Use_Promotion_Yes', 'Booking_Lead_Time', 'Total_Guests'] []\nexpected Booking_channel_Online, Meal_Type_FB, Ethnicity_Asian American, Use_Promotion_Yes, Babies, Gender_M, Ethnicity_caucasian, Discount_Rate, Country_region_West, Ethnicity_Latino, Total_Guests, Room_Rate, Hotel_Type_City Hotel, Income, Deposit_type_Non-Refundable, Country_region_South, Booking_Lead_Time, Meal_Type_HB, Hotel_Type_Resort, Visted_Previously_Yes, Country_region_North, Required_Car_Parking_Yes, Deposit_type_Refundable, Previous_Cancellations_Yes, Adults, Age, Booking_channel_Direct, Educational_Level, Children in input data"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(learning_rate=0.05, n_estimators=300, max_depth=6, eval_metric=\"mlogloss\")\n",
    "xgb_model.fit(X_train_sm, y_train_sm)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "print(\"XGBoost Performance:\\n\", classification_report(y_test, y_pred_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ce7ab-2aa8-43f5-b889-ab38141ab8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hotel_env]",
   "language": "python",
   "name": "conda-env-hotel_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
